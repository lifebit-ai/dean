---
title: "Differential expression analysis with STAR and DEseq2"
output:
  html_document:
    df_print: paged
params:
  feature_counts: "feature_counts_file"
  annotation: "annotation_file"
  condition: "condition"
---

## Using DESeq2 with read counts

This R Markdown takes 3 inputs:

1. The **feature counts** merged TSV file. This can be generated from the generated from **`featureCounts`** & contains the **read counts**. For example, this can be generated by running **[nf-core/rnaseq](https://github.com/nf-core/rnaseq)** using the **STAR** aligner.
2. The **annotation** file containing the samples and their associated metadata, like each condition
3. The **condition** of interest for example one condition we might want to analyse is simply the treatment used on the samples

```{r}
params$feature_counts
params$annotation
params$condition
```

## Preprocessing

### 1. Loading the feature counts

We will be loading & preprocessing the feature counts file:

```{r}
if (params$feature_counts == "counts.RData") {
  load(params$feature_counts)
  counts <- counts$counts
} else {
  counts <- read.csv(params$feature_counts,
                           sep              = "\t",
                           header           = TRUE, 
                           stringsAsFactors = FALSE, 
                           check.names      = FALSE);

  # assign the rownames to the gene ID's & remove uncessary columns
  rownames(counts) <- counts[,1]
  counts <- counts[, -c(1:2)]

  # replace colnames to just the SRA id
  colnames(counts) <- sub("\\_.*", "", colnames(counts))
}
```

### 2. Loading the annotation
Then will have to load the information for the annotation. And make the read count matrix names match the ones in the sample table.

```{r}
# Load sample table with metadata
sampleTable <- read.csv(params$annotation, row.names = 1)

# Remove .bam from the filenames 
colnames(counts) <- gsub("Aligned\\.out\\.bam$" , "", colnames(counts))
```

We are going to make sure we analyse the exactly same samples we have between sample table and count data.

```{r}
# Match and xtract samples for the analysis and keep as a matrix
countdata <- as.matrix(counts)[, colnames(counts) %in% rownames(sampleTable)]
head(countdata)
```

### 3. Setting the conditions of interest

Here we select/extract the one condition we want to analyse, eg the treatment was used on each sample:

```{r}
condition <- unlist(sampleTable[params$condition])
condition
```

## Differential Expression Analysis

Now that we have prepared the sample and counts read data, we can start using DEseq2 as the library to perform Differential Expression analysis.

```{r}
suppressMessages(library(DESeq2))
```

First we create the DEseq dataset object using the read counts and the sample data.

```{r}
dds <- DESeqDataSetFromMatrix(countData=countdata, colData=sampleTable, design= as.formula(paste("~", params$condition)))
dds
```

Then we can run the Differential Expression pipeline with just the command:

```{r}
dds <- DESeq(dds)
```

### Dispersion plot

We can have a look at the dispersion of read counts across genes in all samples

```{r}
plotDispEsts(dds, main="Dispersion plot")
```

### Log Transformation & Histogram

We will then apply log transformation to the read counts and will try to cluster the samples according the log transform counts

```{r}
# Regularized log transformation for clustering/heatmaps, etc
rld <- rlogTransformation(dds)
head(assay(rld))
hist(assay(rld))
```

### Sample Distance Matrix
```{r}
suppressMessages(library(RColorBrewer))
(mycols <- brewer.pal(8, "Dark2")[1:length(unique(condition))])

sampleDists <- as.matrix(dist(t(assay(rld))))
```

By calculating distances across samples from log transformed counts we can plot the distance matrix and colour the samples according to the condition.

```{r}
suppressMessages(library(gplots))
heatmap.2(as.matrix(sampleDists), key=F, trace="none",
          col=colorpanel(100, "black", "white"),
          ColSideColors=mycols[condition], RowSideColors=mycols[condition],
          margin=c(10, 10), main="Sample Distance Matrix")
```

### PCA Biplot
```{r}
rld_pca <- function (rld, intgroup = "condition", ntop = 500, colors=NULL, legendpos="bottomleft", main="PCA Biplot", textcx=1, ...) {
  require(genefilter)
  require(calibrate)
  require(RColorBrewer)
  rv = rowVars(assay(rld))
  select = order(rv, decreasing = TRUE)[seq_len(min(ntop, length(rv)))]
  pca = prcomp(t(assay(rld)[select, ]))
  fac = factor(apply(as.data.frame(colData(rld)[, intgroup, drop = FALSE]), 1, paste, collapse = " : "))
  if (is.null(colors)) {
    if (nlevels(fac) >= 3) {
      colors = brewer.pal(nlevels(fac), "Paired")
    }   else {
      colors = c("black", "red")
    }
  }
  pc1var <- round(summary(pca)$importance[2,1]*100, digits=1)
  pc2var <- round(summary(pca)$importance[2,2]*100, digits=1)
  pc1lab <- paste0("PC1 (",as.character(pc1var),"%)")
  pc2lab <- paste0("PC1 (",as.character(pc2var),"%)")
  plot(PC2~PC1, data=as.data.frame(pca$x), bg=colors[fac], pch=21, xlab=pc1lab, ylab=pc2lab, main=main, ...)
  with(as.data.frame(pca$x), textxy(PC1, PC2, labs=rownames(as.data.frame(pca$x)), cex=textcx))
  legend(legendpos, legend=levels(fac), col=colors, pch=20)
}

```

We can easily use a PCA visualization to see how the variation separates samples, but also how mixed

```{r}
suppressMessages(rld_pca(rld, colors=mycols, intgroup=params$condition, xlim=c(-75, 35)))
```

### Results table of top genes by adjusted p-value

On last steps, we want to be able to filter and to extract genes based on certain thresholds. We can apply filter in order to filter for p-values and adjusted p-values on top of the results table.

```{r}
res <- results(dds)
table(res$padj<0.05)

## Order by adjusted p-value
res <- res[order(res$padj), ]

## Merge with normalized count data
resdata <- merge(as.data.frame(res), as.data.frame(counts(dds, normalized=TRUE)), by="row.names", sort=FALSE)
names(resdata)[1] <- "Gene"
head(resdata)
## Write results
write.csv(resdata, file="diffexpr-results.csv")
```

### Histogram of p-value

There are also several plots available for quality control on top of the results we got that we can explore, like the histogram of significance levels.

```{r}
hist(res$pvalue, breaks=50, col="grey")
```

### MA Plot

```{r}
maplot <- function (res, thresh=0.05, labelsig=TRUE, textcx=1, ...) {
  with(res, plot(baseMean, log2FoldChange, pch=20, cex=.5, log="x", ...))
  with(subset(res, padj<thresh), points(baseMean, log2FoldChange, col="red", pch=20, cex=1.5))
  if (labelsig) {
    require(calibrate)
    with(subset(res, padj<thresh), textxy(baseMean, log2FoldChange, labs=Gene, cex=textcx, col=2))
  }
}
```

Also the MA plot, where we can see how the log fold changes compare against the mean averages across genes

```{r}
maplot(resdata, main="MA Plot")
```

### Volcano plot

The last plot we show is the volcano plot, where we can visualize what's the relationship between log fold changes and significance levels in our test.

```{r}
volcanoplot <- function (res, lfcthresh=2, sigthresh=0.05, main="Volcano Plot", legendpos="bottomright", labelsig=TRUE, textcx=1, ...) {
  with(res, plot(log2FoldChange, -log10(pvalue), pch=20, main=main, ...))
  with(subset(res, padj<sigthresh ), points(log2FoldChange, -log10(pvalue), pch=20, col="red", ...))
  with(subset(res, abs(log2FoldChange)>lfcthresh), points(log2FoldChange, -log10(pvalue), pch=20, col="orange", ...))
  with(subset(res, padj<sigthresh & abs(log2FoldChange)>lfcthresh), points(log2FoldChange, -log10(pvalue), pch=20, col="green", ...))
  if (labelsig) {
    require(calibrate)
    with(subset(res, padj<sigthresh & abs(log2FoldChange)>lfcthresh), textxy(log2FoldChange, -log10(pvalue), labs=Gene, cex=textcx, ...))
  }
  legend(legendpos, xjust=1, yjust=1, legend=c(paste("FDR<",sigthresh,sep=""), paste("|LogFC|>",lfcthresh,sep=""), "both"), pch=20, col=c("red","orange","green"))
}
```

```{r}
volcanoplot(resdata, lfcthresh=2, sigthresh=0.01, textcx=.8, xlim=c(-2.3, 2))
```
